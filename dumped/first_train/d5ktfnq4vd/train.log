INFO - 05/06/22 19:51:14 - 0:00:00 - ============ Initialized logger ============
INFO - 05/06/22 19:51:14 - 0:00:00 - accumulate_gradients: 1
                                     amp: -1
                                     attention_dropout: 0
                                     balanced: False
                                     batch_size: 30
                                     beam_early_stopping: True
                                     beam_eval: False
                                     beam_length_penalty: 1
                                     beam_size: 1
                                     clip_grad_norm: 5
                                     command: python main.py --exp_name first_train --reload_data 'data.prefix.counts.train,data.prefix.counts.valid,data.prefix.counts.test' --reload_size 30 --emb_dim 8 --n_enc_layers 6 --n_dec_layers 6 --n_heads 2 --optimizer 'adam,lr=0.0001' --batch_size 30 --epoch_size 2 --validation_metrics valid_prim_fwd_acc --cpu true --exp_id "d5ktfnq4vd"
                                     cpu: True
                                     datalength: 256
                                     debug: False
                                     debug_slurm: False
                                     dropout: 0
                                     dump_path: ./dumped/first_train/d5ktfnq4vd
                                     emb_dim: 8
                                     env_base_seed: 0
                                     env_name: char_sp
                                     epoch_size: 2
                                     eval_only: False
                                     eval_verbose: 0
                                     eval_verbose_print: False
                                     exp_id: d5ktfnq4vd
                                     exp_name: first_train
                                     export_data: False
                                     fp16: False
                                     global_rank: 0
                                     int_base: 10
                                     is_master: True
                                     is_slurm_job: False
                                     leaf_probs: 0.75,0.25,0
                                     local_rank: 0
                                     master_port: -1
                                     max_epoch: 100000
                                     max_int: 10
                                     max_len: 512
                                     max_ops: 5
                                     multi_gpu: False
                                     multi_node: False
                                     n_dec_layers: 6
                                     n_enc_layers: 6
                                     n_gpu_per_node: 1
                                     n_heads: 2
                                     n_nodes: 1
                                     n_variables: 1
                                     node_id: 0
                                     num_workers: 10
                                     operators: add:2,sub:1
                                     optimizer: adam,lr=0.0001
                                     positive: True
                                     reload_checkpoint: 
                                     reload_data: data.prefix.counts.train,data.prefix.counts.valid,data.prefix.counts.test
                                     reload_model: 
                                     reload_size: 30
                                     rewrite_functions: 
                                     same_nb_ops_per_batch: False
                                     save_periodic: 0
                                     share_inout_emb: True
                                     sinusoidal_embeddings: False
                                     stopping_criterion: 
                                     validation_metrics: valid_prim_fwd_acc
                                     world_size: 1
INFO - 05/06/22 19:51:14 - 0:00:00 - The experiment will be stored in ./dumped/first_train/d5ktfnq4vd
                                     
INFO - 05/06/22 19:51:14 - 0:00:00 - Running command: python main.py --exp_name first_train --reload_data 'data.prefix.counts.train,data.prefix.counts.valid,data.prefix.counts.test' --reload_size 30 --emb_dim 8 --n_enc_layers 6 --n_dec_layers 6 --n_heads 2 --optimizer 'adam,lr=0.0001' --batch_size 30 --epoch_size 2 --validation_metrics valid_prim_fwd_acc --cpu true

WARNING - 05/06/22 19:51:14 - 0:00:00 - Signal handler installed.
INFO - 05/06/22 19:51:14 - 0:00:00 - Unary operators: []
INFO - 05/06/22 19:51:14 - 0:00:00 - Binary operators: ['add', 'sub']
INFO - 05/06/22 19:51:14 - 0:00:00 - words: {'<s>': 0, '</s>': 1, '<pad>': 2, '(': 3, ')': 4, 'pi': 5, 'x': 6, 'abs': 7, 'acos': 8, 'acosh': 9, 'acot': 10, 'acoth': 11, 'acsc': 12, 'acsch': 13, 'add': 14, 'asec': 15, 'asech': 16, 'asin': 17, 'asinh': 18, 'atan': 19, 'atanh': 20, 'cos': 21, 'cosh': 22, 'cot': 23, 'coth': 24, 'csc': 25, 'csch': 26, 'div': 27, 'exp': 28, 'inv': 29, 'ln': 30, 'mul': 31, 'pow': 32, 'pow2': 33, 'pow3': 34, 'pow4': 35, 'pow5': 36, 'rac': 37, 'sec': 38, 'sech': 39, 'sign': 40, 'sin': 41, 'sinh': 42, 'sqrt': 43, 'sub': 44, 'tan': 45, 'tanh': 46, 'INT+': 47, 'INT-': 48, 'INT': 49, '0': 50, '1': 51, '2': 52, '3': 53, '4': 54, '5': 55, '6': 56, '7': 57, '8': 58, '9': 59}
INFO - 05/06/22 19:51:14 - 0:00:00 - 11 possible leaves.
INFO - 05/06/22 19:51:14 - 0:00:00 - Checking expressions in [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 2.1, 3.1, -0.01, -0.1, -0.3, -0.5, -0.7, -0.9, -1.1, -2.1, -3.1]
DEBUG - 05/06/22 19:51:14 - 0:00:00 - TransformerModel(
                                        (position_embeddings): Embedding(4096, 8)
                                        (embeddings): Embedding(60, 8, padding_idx=1)
                                        (layer_norm_emb): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        (attentions): ModuleList(
                                          (0): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (1): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (2): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (3): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (4): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (5): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm1): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (ffns): ModuleList(
                                          (0): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (1): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (2): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (3): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (4): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (5): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm2): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                      ): TransformerModel(
                                        (position_embeddings): Embedding(4096, 8)
                                        (embeddings): Embedding(60, 8, padding_idx=1)
                                        (layer_norm_emb): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        (attentions): ModuleList(
                                          (0): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (1): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (2): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (3): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (4): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (5): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm1): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (ffns): ModuleList(
                                          (0): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (1): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (2): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (3): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (4): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (5): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm2): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                      )
DEBUG - 05/06/22 19:51:14 - 0:00:00 - TransformerModel(
                                        (position_embeddings): Embedding(4096, 8)
                                        (embeddings): Embedding(60, 8, padding_idx=1)
                                        (layer_norm_emb): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        (attentions): ModuleList(
                                          (0): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (1): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (2): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (3): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (4): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (5): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm1): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (ffns): ModuleList(
                                          (0): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (1): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (2): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (3): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (4): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (5): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm2): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (layer_norm15): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (encoder_attn): ModuleList(
                                          (0): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (1): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (2): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (3): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (4): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (5): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                        )
                                        (proj): Linear(in_features=8, out_features=60, bias=True)
                                      ): TransformerModel(
                                        (position_embeddings): Embedding(4096, 8)
                                        (embeddings): Embedding(60, 8, padding_idx=1)
                                        (layer_norm_emb): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        (attentions): ModuleList(
                                          (0): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (1): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (2): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (3): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (4): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (5): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm1): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (ffns): ModuleList(
                                          (0): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (1): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (2): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (3): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (4): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                          (5): TransformerFFN(
                                            (lin1): Linear(in_features=8, out_features=32, bias=True)
                                            (lin2): Linear(in_features=32, out_features=8, bias=True)
                                          )
                                        )
                                        (layer_norm2): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (layer_norm15): ModuleList(
                                          (0): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (1): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (2): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (3): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (4): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                          (5): LayerNorm((8,), eps=1e-12, elementwise_affine=True)
                                        )
                                        (encoder_attn): ModuleList(
                                          (0): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (1): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (2): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (3): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (4): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                          (5): MultiHeadAttention(
                                            (q_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (k_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (v_lin): Linear(in_features=8, out_features=8, bias=True)
                                            (out_lin): Linear(in_features=8, out_features=8, bias=True)
                                          )
                                        )
                                        (proj): Linear(in_features=8, out_features=60, bias=True)
                                      )
INFO - 05/06/22 19:51:14 - 0:00:00 - Number of parameters (encoder): 38496
INFO - 05/06/22 19:51:14 - 0:00:00 - Number of parameters (decoder): 40380
INFO - 05/06/22 19:51:14 - 0:00:00 - Found 261 parameters in model.
INFO - 05/06/22 19:51:14 - 0:00:00 - Optimizers: model
INFO - 05/06/22 19:51:14 - 0:00:00 - Creating train iterator  ...
INFO - 05/06/22 19:51:14 - 0:00:00 - Loading data from data.prefix.counts.train ...
INFO - 05/06/22 19:51:14 - 0:00:00 - Loaded 28 equations from the disk.
INFO - 05/06/22 19:51:15 - 0:00:01 - ============ Starting epoch 0 ... ============
WARNING - 05/06/22 19:51:16 - 0:00:02 - NaN detected
INFO - 05/06/22 19:51:16 - 0:00:02 - ============ End of epoch 0 ============
INFO - 05/06/22 19:51:16 - 0:00:02 - Creating valid iterator for ...
INFO - 05/06/22 19:51:16 - 0:00:02 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:51:16 - 0:00:02 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:51:17 - 0:00:03 - 0/2
INFO - 05/06/22 19:51:22 - 0:00:08 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:51:22 - 0:00:08 - Creating test iterator for ...
INFO - 05/06/22 19:51:22 - 0:00:08 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:51:22 - 0:00:08 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:51:24 - 0:00:09 - 0/2
INFO - 05/06/22 19:51:29 - 0:00:14 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:51:29 - 0:00:14 - epoch -> 0.000000
INFO - 05/06/22 19:51:29 - 0:00:14 - valid_xe_loss -> nan
INFO - 05/06/22 19:51:29 - 0:00:14 - valid_acc -> 0.000000
INFO - 05/06/22 19:51:29 - 0:00:14 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:51:29 - 0:00:14 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:51:29 - 0:00:14 - test_xe_loss -> nan
INFO - 05/06/22 19:51:29 - 0:00:14 - test_acc -> 0.000000
INFO - 05/06/22 19:51:29 - 0:00:14 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:51:29 - 0:00:14 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:51:29 - 0:00:14 - __log__:{"epoch": 0, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:51:29 - 0:00:14 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:51:29 - 0:00:14 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:51:29 - 0:00:14 - Saving encoder parameters ...
WARNING - 05/06/22 19:51:29 - 0:00:14 - Saving decoder parameters ...
WARNING - 05/06/22 19:51:29 - 0:00:14 - Saving model optimizer ...
INFO - 05/06/22 19:51:29 - 0:00:14 - ============ Starting epoch 1 ... ============
WARNING - 05/06/22 19:51:29 - 0:00:15 - NaN detected
INFO - 05/06/22 19:51:29 - 0:00:15 - ============ End of epoch 1 ============
INFO - 05/06/22 19:51:29 - 0:00:15 - Creating valid iterator for ...
INFO - 05/06/22 19:51:29 - 0:00:15 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:51:29 - 0:00:15 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:51:30 - 0:00:16 - 0/2
INFO - 05/06/22 19:51:35 - 0:00:21 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:51:35 - 0:00:21 - Creating test iterator for ...
INFO - 05/06/22 19:51:35 - 0:00:21 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:51:35 - 0:00:21 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:51:37 - 0:00:22 - 0/2
INFO - 05/06/22 19:51:42 - 0:00:27 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:51:42 - 0:00:27 - epoch -> 1.000000
INFO - 05/06/22 19:51:42 - 0:00:27 - valid_xe_loss -> nan
INFO - 05/06/22 19:51:42 - 0:00:27 - valid_acc -> 0.000000
INFO - 05/06/22 19:51:42 - 0:00:27 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:51:42 - 0:00:27 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:51:42 - 0:00:27 - test_xe_loss -> nan
INFO - 05/06/22 19:51:42 - 0:00:27 - test_acc -> 0.000000
INFO - 05/06/22 19:51:42 - 0:00:27 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:51:42 - 0:00:27 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:51:42 - 0:00:27 - __log__:{"epoch": 1, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:51:42 - 0:00:27 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:51:42 - 0:00:27 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:51:42 - 0:00:27 - Saving encoder parameters ...
WARNING - 05/06/22 19:51:42 - 0:00:27 - Saving decoder parameters ...
WARNING - 05/06/22 19:51:42 - 0:00:27 - Saving model optimizer ...
INFO - 05/06/22 19:51:42 - 0:00:27 - ============ Starting epoch 2 ... ============
WARNING - 05/06/22 19:51:42 - 0:00:28 - NaN detected
INFO - 05/06/22 19:51:42 - 0:00:28 - ============ End of epoch 2 ============
INFO - 05/06/22 19:51:42 - 0:00:28 - Creating valid iterator for ...
INFO - 05/06/22 19:51:42 - 0:00:28 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:51:42 - 0:00:28 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:51:43 - 0:00:29 - 0/2
INFO - 05/06/22 19:51:48 - 0:00:34 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:51:48 - 0:00:34 - Creating test iterator for ...
INFO - 05/06/22 19:51:48 - 0:00:34 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:51:48 - 0:00:34 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:51:50 - 0:00:35 - 0/2
INFO - 05/06/22 19:51:55 - 0:00:40 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:51:55 - 0:00:40 - epoch -> 2.000000
INFO - 05/06/22 19:51:55 - 0:00:40 - valid_xe_loss -> nan
INFO - 05/06/22 19:51:55 - 0:00:40 - valid_acc -> 0.000000
INFO - 05/06/22 19:51:55 - 0:00:40 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:51:55 - 0:00:40 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:51:55 - 0:00:40 - test_xe_loss -> nan
INFO - 05/06/22 19:51:55 - 0:00:40 - test_acc -> 0.000000
INFO - 05/06/22 19:51:55 - 0:00:40 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:51:55 - 0:00:40 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:51:55 - 0:00:40 - __log__:{"epoch": 2, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:51:55 - 0:00:40 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:51:55 - 0:00:40 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:51:55 - 0:00:40 - Saving encoder parameters ...
WARNING - 05/06/22 19:51:55 - 0:00:40 - Saving decoder parameters ...
WARNING - 05/06/22 19:51:55 - 0:00:40 - Saving model optimizer ...
INFO - 05/06/22 19:51:55 - 0:00:40 - ============ Starting epoch 3 ... ============
WARNING - 05/06/22 19:51:55 - 0:00:40 - NaN detected
INFO - 05/06/22 19:51:55 - 0:00:41 - ============ End of epoch 3 ============
INFO - 05/06/22 19:51:55 - 0:00:41 - Creating valid iterator for ...
INFO - 05/06/22 19:51:55 - 0:00:41 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:51:55 - 0:00:41 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:51:56 - 0:00:42 - 0/2
INFO - 05/06/22 19:52:01 - 0:00:47 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:01 - 0:00:47 - Creating test iterator for ...
INFO - 05/06/22 19:52:01 - 0:00:47 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:52:01 - 0:00:47 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:03 - 0:00:49 - 0/2
INFO - 05/06/22 19:52:08 - 0:00:54 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:08 - 0:00:54 - epoch -> 3.000000
INFO - 05/06/22 19:52:08 - 0:00:54 - valid_xe_loss -> nan
INFO - 05/06/22 19:52:08 - 0:00:54 - valid_acc -> 0.000000
INFO - 05/06/22 19:52:08 - 0:00:54 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:52:08 - 0:00:54 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:52:08 - 0:00:54 - test_xe_loss -> nan
INFO - 05/06/22 19:52:08 - 0:00:54 - test_acc -> 0.000000
INFO - 05/06/22 19:52:08 - 0:00:54 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:52:08 - 0:00:54 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:52:08 - 0:00:54 - __log__:{"epoch": 3, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:52:08 - 0:00:54 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:52:08 - 0:00:54 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:52:08 - 0:00:54 - Saving encoder parameters ...
WARNING - 05/06/22 19:52:08 - 0:00:54 - Saving decoder parameters ...
WARNING - 05/06/22 19:52:08 - 0:00:54 - Saving model optimizer ...
INFO - 05/06/22 19:52:08 - 0:00:54 - ============ Starting epoch 4 ... ============
WARNING - 05/06/22 19:52:08 - 0:00:54 - NaN detected
INFO - 05/06/22 19:52:08 - 0:00:54 - ============ End of epoch 4 ============
INFO - 05/06/22 19:52:08 - 0:00:54 - Creating valid iterator for ...
INFO - 05/06/22 19:52:08 - 0:00:54 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:52:08 - 0:00:54 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:09 - 0:00:55 - 0/2
INFO - 05/06/22 19:52:14 - 0:01:00 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:14 - 0:01:00 - Creating test iterator for ...
INFO - 05/06/22 19:52:14 - 0:01:00 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:52:14 - 0:01:00 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:16 - 0:01:02 - 0/2
INFO - 05/06/22 19:52:21 - 0:01:07 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:21 - 0:01:07 - epoch -> 4.000000
INFO - 05/06/22 19:52:21 - 0:01:07 - valid_xe_loss -> nan
INFO - 05/06/22 19:52:21 - 0:01:07 - valid_acc -> 0.000000
INFO - 05/06/22 19:52:21 - 0:01:07 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:52:21 - 0:01:07 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:52:21 - 0:01:07 - test_xe_loss -> nan
INFO - 05/06/22 19:52:21 - 0:01:07 - test_acc -> 0.000000
INFO - 05/06/22 19:52:21 - 0:01:07 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:52:21 - 0:01:07 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:52:21 - 0:01:07 - __log__:{"epoch": 4, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:52:21 - 0:01:07 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:52:21 - 0:01:07 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:52:21 - 0:01:07 - Saving encoder parameters ...
WARNING - 05/06/22 19:52:21 - 0:01:07 - Saving decoder parameters ...
WARNING - 05/06/22 19:52:21 - 0:01:07 - Saving model optimizer ...
INFO - 05/06/22 19:52:21 - 0:01:07 - ============ Starting epoch 5 ... ============
WARNING - 05/06/22 19:52:21 - 0:01:07 - NaN detected
INFO - 05/06/22 19:52:21 - 0:01:07 - ============ End of epoch 5 ============
INFO - 05/06/22 19:52:21 - 0:01:07 - Creating valid iterator for ...
INFO - 05/06/22 19:52:21 - 0:01:07 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:52:21 - 0:01:07 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:23 - 0:01:09 - 0/2
INFO - 05/06/22 19:52:28 - 0:01:14 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:28 - 0:01:14 - Creating test iterator for ...
INFO - 05/06/22 19:52:28 - 0:01:14 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:52:28 - 0:01:14 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:29 - 0:01:15 - 0/2
INFO - 05/06/22 19:52:34 - 0:01:20 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:34 - 0:01:20 - epoch -> 5.000000
INFO - 05/06/22 19:52:34 - 0:01:20 - valid_xe_loss -> nan
INFO - 05/06/22 19:52:34 - 0:01:20 - valid_acc -> 0.000000
INFO - 05/06/22 19:52:34 - 0:01:20 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:52:34 - 0:01:20 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:52:34 - 0:01:20 - test_xe_loss -> nan
INFO - 05/06/22 19:52:34 - 0:01:20 - test_acc -> 0.000000
INFO - 05/06/22 19:52:34 - 0:01:20 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:52:34 - 0:01:20 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:52:34 - 0:01:20 - __log__:{"epoch": 5, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:52:34 - 0:01:20 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:52:34 - 0:01:20 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:52:34 - 0:01:20 - Saving encoder parameters ...
WARNING - 05/06/22 19:52:34 - 0:01:20 - Saving decoder parameters ...
WARNING - 05/06/22 19:52:34 - 0:01:20 - Saving model optimizer ...
INFO - 05/06/22 19:52:34 - 0:01:20 - ============ Starting epoch 6 ... ============
WARNING - 05/06/22 19:52:34 - 0:01:20 - NaN detected
INFO - 05/06/22 19:52:34 - 0:01:20 - ============ End of epoch 6 ============
INFO - 05/06/22 19:52:34 - 0:01:20 - Creating valid iterator for ...
INFO - 05/06/22 19:52:34 - 0:01:20 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:52:34 - 0:01:20 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:36 - 0:01:22 - 0/2
INFO - 05/06/22 19:52:41 - 0:01:27 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:41 - 0:01:27 - Creating test iterator for ...
INFO - 05/06/22 19:52:41 - 0:01:27 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:52:41 - 0:01:27 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:43 - 0:01:28 - 0/2
INFO - 05/06/22 19:52:48 - 0:01:33 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:48 - 0:01:33 - epoch -> 6.000000
INFO - 05/06/22 19:52:48 - 0:01:33 - valid_xe_loss -> nan
INFO - 05/06/22 19:52:48 - 0:01:33 - valid_acc -> 0.000000
INFO - 05/06/22 19:52:48 - 0:01:33 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:52:48 - 0:01:33 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:52:48 - 0:01:33 - test_xe_loss -> nan
INFO - 05/06/22 19:52:48 - 0:01:33 - test_acc -> 0.000000
INFO - 05/06/22 19:52:48 - 0:01:33 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:52:48 - 0:01:33 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:52:48 - 0:01:33 - __log__:{"epoch": 6, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:52:48 - 0:01:33 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:52:48 - 0:01:33 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:52:48 - 0:01:33 - Saving encoder parameters ...
WARNING - 05/06/22 19:52:48 - 0:01:33 - Saving decoder parameters ...
WARNING - 05/06/22 19:52:48 - 0:01:33 - Saving model optimizer ...
INFO - 05/06/22 19:52:48 - 0:01:34 - ============ Starting epoch 7 ... ============
WARNING - 05/06/22 19:52:48 - 0:01:34 - NaN detected
INFO - 05/06/22 19:52:48 - 0:01:34 - ============ End of epoch 7 ============
INFO - 05/06/22 19:52:48 - 0:01:34 - Creating valid iterator for ...
INFO - 05/06/22 19:52:48 - 0:01:34 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:52:48 - 0:01:34 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:49 - 0:01:35 - 0/2
INFO - 05/06/22 19:52:54 - 0:01:40 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:52:54 - 0:01:40 - Creating test iterator for ...
INFO - 05/06/22 19:52:54 - 0:01:40 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:52:54 - 0:01:40 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:52:56 - 0:01:41 - 0/2
INFO - 05/06/22 19:53:01 - 0:01:46 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:01 - 0:01:46 - epoch -> 7.000000
INFO - 05/06/22 19:53:01 - 0:01:46 - valid_xe_loss -> nan
INFO - 05/06/22 19:53:01 - 0:01:46 - valid_acc -> 0.000000
INFO - 05/06/22 19:53:01 - 0:01:46 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:53:01 - 0:01:46 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:53:01 - 0:01:46 - test_xe_loss -> nan
INFO - 05/06/22 19:53:01 - 0:01:46 - test_acc -> 0.000000
INFO - 05/06/22 19:53:01 - 0:01:46 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:53:01 - 0:01:46 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:53:01 - 0:01:46 - __log__:{"epoch": 7, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:53:01 - 0:01:46 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:53:01 - 0:01:46 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:53:01 - 0:01:46 - Saving encoder parameters ...
WARNING - 05/06/22 19:53:01 - 0:01:46 - Saving decoder parameters ...
WARNING - 05/06/22 19:53:01 - 0:01:46 - Saving model optimizer ...
INFO - 05/06/22 19:53:01 - 0:01:46 - ============ Starting epoch 8 ... ============
WARNING - 05/06/22 19:53:01 - 0:01:47 - NaN detected
INFO - 05/06/22 19:53:01 - 0:01:47 - ============ End of epoch 8 ============
INFO - 05/06/22 19:53:01 - 0:01:47 - Creating valid iterator for ...
INFO - 05/06/22 19:53:01 - 0:01:47 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:53:01 - 0:01:47 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:02 - 0:01:48 - 0/2
INFO - 05/06/22 19:53:07 - 0:01:53 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:07 - 0:01:53 - Creating test iterator for ...
INFO - 05/06/22 19:53:07 - 0:01:53 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:53:07 - 0:01:53 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:09 - 0:01:55 - 0/2
INFO - 05/06/22 19:53:14 - 0:02:00 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:14 - 0:02:00 - epoch -> 8.000000
INFO - 05/06/22 19:53:14 - 0:02:00 - valid_xe_loss -> nan
INFO - 05/06/22 19:53:14 - 0:02:00 - valid_acc -> 0.000000
INFO - 05/06/22 19:53:14 - 0:02:00 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:53:14 - 0:02:00 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:53:14 - 0:02:00 - test_xe_loss -> nan
INFO - 05/06/22 19:53:14 - 0:02:00 - test_acc -> 0.000000
INFO - 05/06/22 19:53:14 - 0:02:00 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:53:14 - 0:02:00 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:53:14 - 0:02:00 - __log__:{"epoch": 8, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:53:14 - 0:02:00 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:53:14 - 0:02:00 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:53:14 - 0:02:00 - Saving encoder parameters ...
WARNING - 05/06/22 19:53:14 - 0:02:00 - Saving decoder parameters ...
WARNING - 05/06/22 19:53:14 - 0:02:00 - Saving model optimizer ...
INFO - 05/06/22 19:53:14 - 0:02:00 - ============ Starting epoch 9 ... ============
WARNING - 05/06/22 19:53:14 - 0:02:00 - NaN detected
INFO - 05/06/22 19:53:14 - 0:02:00 - ============ End of epoch 9 ============
INFO - 05/06/22 19:53:14 - 0:02:00 - Creating valid iterator for ...
INFO - 05/06/22 19:53:14 - 0:02:00 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:53:14 - 0:02:00 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:15 - 0:02:01 - 0/2
INFO - 05/06/22 19:53:20 - 0:02:06 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:20 - 0:02:06 - Creating test iterator for ...
INFO - 05/06/22 19:53:20 - 0:02:06 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:53:20 - 0:02:06 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:22 - 0:02:08 - 0/2
INFO - 05/06/22 19:53:27 - 0:02:13 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:27 - 0:02:13 - epoch -> 9.000000
INFO - 05/06/22 19:53:27 - 0:02:13 - valid_xe_loss -> nan
INFO - 05/06/22 19:53:27 - 0:02:13 - valid_acc -> 0.000000
INFO - 05/06/22 19:53:27 - 0:02:13 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:53:27 - 0:02:13 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:53:27 - 0:02:13 - test_xe_loss -> nan
INFO - 05/06/22 19:53:27 - 0:02:13 - test_acc -> 0.000000
INFO - 05/06/22 19:53:27 - 0:02:13 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:53:27 - 0:02:13 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:53:27 - 0:02:13 - __log__:{"epoch": 9, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:53:27 - 0:02:13 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:53:27 - 0:02:13 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:53:27 - 0:02:13 - Saving encoder parameters ...
WARNING - 05/06/22 19:53:27 - 0:02:13 - Saving decoder parameters ...
WARNING - 05/06/22 19:53:27 - 0:02:13 - Saving model optimizer ...
INFO - 05/06/22 19:53:27 - 0:02:13 - ============ Starting epoch 10 ... ============
WARNING - 05/06/22 19:53:27 - 0:02:13 - NaN detected
INFO - 05/06/22 19:53:27 - 0:02:13 - ============ End of epoch 10 ============
INFO - 05/06/22 19:53:27 - 0:02:13 - Creating valid iterator for ...
INFO - 05/06/22 19:53:27 - 0:02:13 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:53:27 - 0:02:13 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:29 - 0:02:14 - 0/2
INFO - 05/06/22 19:53:34 - 0:02:19 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:34 - 0:02:19 - Creating test iterator for ...
INFO - 05/06/22 19:53:34 - 0:02:19 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:53:34 - 0:02:20 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:35 - 0:02:21 - 0/2
INFO - 05/06/22 19:53:40 - 0:02:26 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:40 - 0:02:26 - epoch -> 10.000000
INFO - 05/06/22 19:53:40 - 0:02:26 - valid_xe_loss -> nan
INFO - 05/06/22 19:53:40 - 0:02:26 - valid_acc -> 0.000000
INFO - 05/06/22 19:53:40 - 0:02:26 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:53:40 - 0:02:26 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:53:40 - 0:02:26 - test_xe_loss -> nan
INFO - 05/06/22 19:53:40 - 0:02:26 - test_acc -> 0.000000
INFO - 05/06/22 19:53:40 - 0:02:26 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:53:40 - 0:02:26 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:53:40 - 0:02:26 - __log__:{"epoch": 10, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:53:40 - 0:02:26 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:53:40 - 0:02:26 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:53:40 - 0:02:26 - Saving encoder parameters ...
WARNING - 05/06/22 19:53:40 - 0:02:26 - Saving decoder parameters ...
WARNING - 05/06/22 19:53:40 - 0:02:26 - Saving model optimizer ...
INFO - 05/06/22 19:53:40 - 0:02:26 - ============ Starting epoch 11 ... ============
WARNING - 05/06/22 19:53:40 - 0:02:26 - NaN detected
INFO - 05/06/22 19:53:40 - 0:02:26 - ============ End of epoch 11 ============
INFO - 05/06/22 19:53:40 - 0:02:26 - Creating valid iterator for ...
INFO - 05/06/22 19:53:40 - 0:02:26 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:53:40 - 0:02:26 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:42 - 0:02:27 - 0/2
INFO - 05/06/22 19:53:47 - 0:02:33 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:47 - 0:02:33 - Creating test iterator for ...
INFO - 05/06/22 19:53:47 - 0:02:33 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:53:47 - 0:02:33 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:48 - 0:02:34 - 0/2
INFO - 05/06/22 19:53:53 - 0:02:39 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:53:53 - 0:02:39 - epoch -> 11.000000
INFO - 05/06/22 19:53:53 - 0:02:39 - valid_xe_loss -> nan
INFO - 05/06/22 19:53:53 - 0:02:39 - valid_acc -> 0.000000
INFO - 05/06/22 19:53:53 - 0:02:39 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:53:53 - 0:02:39 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:53:53 - 0:02:39 - test_xe_loss -> nan
INFO - 05/06/22 19:53:53 - 0:02:39 - test_acc -> 0.000000
INFO - 05/06/22 19:53:53 - 0:02:39 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:53:53 - 0:02:39 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:53:53 - 0:02:39 - __log__:{"epoch": 11, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:53:53 - 0:02:39 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:53:53 - 0:02:39 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:53:53 - 0:02:39 - Saving encoder parameters ...
WARNING - 05/06/22 19:53:53 - 0:02:39 - Saving decoder parameters ...
WARNING - 05/06/22 19:53:53 - 0:02:39 - Saving model optimizer ...
INFO - 05/06/22 19:53:53 - 0:02:39 - ============ Starting epoch 12 ... ============
WARNING - 05/06/22 19:53:53 - 0:02:39 - NaN detected
INFO - 05/06/22 19:53:53 - 0:02:39 - ============ End of epoch 12 ============
INFO - 05/06/22 19:53:53 - 0:02:39 - Creating valid iterator for ...
INFO - 05/06/22 19:53:53 - 0:02:39 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:53:53 - 0:02:39 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:53:55 - 0:02:41 - 0/2
INFO - 05/06/22 19:54:00 - 0:02:46 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:00 - 0:02:46 - Creating test iterator for ...
INFO - 05/06/22 19:54:00 - 0:02:46 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:54:00 - 0:02:46 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:01 - 0:02:47 - 0/2
INFO - 05/06/22 19:54:06 - 0:02:52 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:06 - 0:02:52 - epoch -> 12.000000
INFO - 05/06/22 19:54:06 - 0:02:52 - valid_xe_loss -> nan
INFO - 05/06/22 19:54:06 - 0:02:52 - valid_acc -> 0.000000
INFO - 05/06/22 19:54:06 - 0:02:52 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:54:06 - 0:02:52 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:54:06 - 0:02:52 - test_xe_loss -> nan
INFO - 05/06/22 19:54:06 - 0:02:52 - test_acc -> 0.000000
INFO - 05/06/22 19:54:06 - 0:02:52 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:54:06 - 0:02:52 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:54:06 - 0:02:52 - __log__:{"epoch": 12, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:54:06 - 0:02:52 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:54:06 - 0:02:52 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:54:06 - 0:02:52 - Saving encoder parameters ...
WARNING - 05/06/22 19:54:06 - 0:02:52 - Saving decoder parameters ...
WARNING - 05/06/22 19:54:06 - 0:02:52 - Saving model optimizer ...
INFO - 05/06/22 19:54:06 - 0:02:52 - ============ Starting epoch 13 ... ============
WARNING - 05/06/22 19:54:06 - 0:02:52 - NaN detected
INFO - 05/06/22 19:54:06 - 0:02:52 - ============ End of epoch 13 ============
INFO - 05/06/22 19:54:06 - 0:02:52 - Creating valid iterator for ...
INFO - 05/06/22 19:54:06 - 0:02:52 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:54:06 - 0:02:52 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:08 - 0:02:54 - 0/2
INFO - 05/06/22 19:54:13 - 0:02:59 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:13 - 0:02:59 - Creating test iterator for ...
INFO - 05/06/22 19:54:13 - 0:02:59 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:54:13 - 0:02:59 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:14 - 0:03:00 - 0/2
INFO - 05/06/22 19:54:19 - 0:03:05 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:19 - 0:03:05 - epoch -> 13.000000
INFO - 05/06/22 19:54:19 - 0:03:05 - valid_xe_loss -> nan
INFO - 05/06/22 19:54:19 - 0:03:05 - valid_acc -> 0.000000
INFO - 05/06/22 19:54:19 - 0:03:05 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:54:19 - 0:03:05 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:54:19 - 0:03:05 - test_xe_loss -> nan
INFO - 05/06/22 19:54:19 - 0:03:05 - test_acc -> 0.000000
INFO - 05/06/22 19:54:19 - 0:03:05 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:54:19 - 0:03:05 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:54:19 - 0:03:05 - __log__:{"epoch": 13, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:54:19 - 0:03:05 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:54:19 - 0:03:05 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:54:19 - 0:03:05 - Saving encoder parameters ...
WARNING - 05/06/22 19:54:19 - 0:03:05 - Saving decoder parameters ...
WARNING - 05/06/22 19:54:19 - 0:03:05 - Saving model optimizer ...
INFO - 05/06/22 19:54:19 - 0:03:05 - ============ Starting epoch 14 ... ============
WARNING - 05/06/22 19:54:19 - 0:03:05 - NaN detected
INFO - 05/06/22 19:54:20 - 0:03:05 - ============ End of epoch 14 ============
INFO - 05/06/22 19:54:20 - 0:03:05 - Creating valid iterator for ...
INFO - 05/06/22 19:54:20 - 0:03:05 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:54:20 - 0:03:05 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:21 - 0:03:07 - 0/2
INFO - 05/06/22 19:54:26 - 0:03:12 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:26 - 0:03:12 - Creating test iterator for ...
INFO - 05/06/22 19:54:26 - 0:03:12 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:54:26 - 0:03:12 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:28 - 0:03:13 - 0/2
INFO - 05/06/22 19:54:33 - 0:03:18 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:33 - 0:03:18 - epoch -> 14.000000
INFO - 05/06/22 19:54:33 - 0:03:18 - valid_xe_loss -> nan
INFO - 05/06/22 19:54:33 - 0:03:18 - valid_acc -> 0.000000
INFO - 05/06/22 19:54:33 - 0:03:18 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:54:33 - 0:03:18 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:54:33 - 0:03:18 - test_xe_loss -> nan
INFO - 05/06/22 19:54:33 - 0:03:18 - test_acc -> 0.000000
INFO - 05/06/22 19:54:33 - 0:03:18 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:54:33 - 0:03:18 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:54:33 - 0:03:18 - __log__:{"epoch": 14, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:54:33 - 0:03:18 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:54:33 - 0:03:18 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:54:33 - 0:03:18 - Saving encoder parameters ...
WARNING - 05/06/22 19:54:33 - 0:03:18 - Saving decoder parameters ...
WARNING - 05/06/22 19:54:33 - 0:03:18 - Saving model optimizer ...
INFO - 05/06/22 19:54:33 - 0:03:18 - ============ Starting epoch 15 ... ============
WARNING - 05/06/22 19:54:33 - 0:03:19 - NaN detected
INFO - 05/06/22 19:54:33 - 0:03:19 - ============ End of epoch 15 ============
INFO - 05/06/22 19:54:33 - 0:03:19 - Creating valid iterator for ...
INFO - 05/06/22 19:54:33 - 0:03:19 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:54:33 - 0:03:19 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:34 - 0:03:20 - 0/2
INFO - 05/06/22 19:54:39 - 0:03:25 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:39 - 0:03:25 - Creating test iterator for ...
INFO - 05/06/22 19:54:39 - 0:03:25 - Loading data from data.prefix.counts.test ...
INFO - 05/06/22 19:54:39 - 0:03:25 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:41 - 0:03:27 - 0/2
INFO - 05/06/22 19:54:46 - 0:03:32 - 0/2 (0.0%) equations were evaluated correctly.
INFO - 05/06/22 19:54:46 - 0:03:32 - epoch -> 15.000000
INFO - 05/06/22 19:54:46 - 0:03:32 - valid_xe_loss -> nan
INFO - 05/06/22 19:54:46 - 0:03:32 - valid_acc -> 0.000000
INFO - 05/06/22 19:54:46 - 0:03:32 - valid_acc_0 -> 0.000000
INFO - 05/06/22 19:54:46 - 0:03:32 - valid_acc_4 -> 0.000000
INFO - 05/06/22 19:54:46 - 0:03:32 - test_xe_loss -> nan
INFO - 05/06/22 19:54:46 - 0:03:32 - test_acc -> 0.000000
INFO - 05/06/22 19:54:46 - 0:03:32 - test_acc_3 -> 0.000000
INFO - 05/06/22 19:54:46 - 0:03:32 - test_acc_4 -> 0.000000
INFO - 05/06/22 19:54:46 - 0:03:32 - __log__:{"epoch": 15, "valid_xe_loss": NaN, "valid_acc": 0.0, "valid_acc_0": 0.0, "valid_acc_4": 0.0, "test_xe_loss": NaN, "test_acc": 0.0, "test_acc_3": 0.0, "test_acc_4": 0.0}
WARNING - 05/06/22 19:54:46 - 0:03:32 - Metric "valid_prim_fwd_acc" not found in scores!
INFO - 05/06/22 19:54:46 - 0:03:32 - Saving checkpoint to ./dumped/first_train/d5ktfnq4vd/checkpoint.pth ...
WARNING - 05/06/22 19:54:46 - 0:03:32 - Saving encoder parameters ...
WARNING - 05/06/22 19:54:46 - 0:03:32 - Saving decoder parameters ...
WARNING - 05/06/22 19:54:46 - 0:03:32 - Saving model optimizer ...
INFO - 05/06/22 19:54:46 - 0:03:32 - ============ Starting epoch 16 ... ============
WARNING - 05/06/22 19:54:46 - 0:03:32 - NaN detected
INFO - 05/06/22 19:54:46 - 0:03:32 - ============ End of epoch 16 ============
INFO - 05/06/22 19:54:46 - 0:03:32 - Creating valid iterator for ...
INFO - 05/06/22 19:54:46 - 0:03:32 - Loading data from data.prefix.counts.valid ...
INFO - 05/06/22 19:54:46 - 0:03:32 - Loaded 2 equations from the disk.
INFO - 05/06/22 19:54:47 - 0:03:33 - 0/2
